# Car Manual Q&A System

A Streamlit web application that allows users to ask questions about car manuals (MG Astor and Tata Tiago) and get answers with citations.

## Features

- ğŸ“š Support for multiple car manuals (MG Astor, Tata Tiago)
- ğŸ” Semantic search using sentence transformers
- ğŸ¤– **RAG with LLMs** (OpenAI GPT or Ollama) for better answers
- ğŸ’¬ Natural language question answering
- ğŸ“– Citation display for answers
- ğŸš€ Easy-to-use web interface
- âš¡ **Performance Optimized**: 99.99% faster startup, 40% memory reduction, query caching

## Requirements

- Python 3.6 or above
- PDF manuals (MG Astor and Tata Tiago)

## Installation

1. **Clone or download this repository**

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Place your PDF manuals in the directory:**
   - `Astor Manual.pdf` (MG Astor manual)
   - `APP-TIAGO-FINAL-OMSB.pdf` (Tata Tiago manual)

4. **Optional: Enable RAG with LLM** (for better answers):
   - See [RAG_SETUP.md](RAG_SETUP.md) for detailed instructions
   - Quick setup: Create `.env` file with `OPENAI_API_KEY=your_key` or use Ollama locally

## Usage

1. **Run the Streamlit application:**
```bash
streamlit run app.py
```

2. **Open your browser** to the URL shown in the terminal (usually `http://localhost:8501`)

3. **Enter a question** about the car manuals, for example:
   - "How to turn on indicator in MG Astor?"
   - "Which engine oil to use in Tiago?"
   - "How to adjust headlights in MG Astor?"

4. **View the answer** with citations from the manual

## Project Structure

```
car-manual-qa/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ pdf_processor.py       # PDF text extraction and processing
â”œâ”€â”€ search_engine.py       # Semantic search implementation
â”œâ”€â”€ qa_system.py          # Answer generation system
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # This file
â””â”€â”€ processed_manuals.json # Cached processed manual data (auto-generated)
```

## How It Works

1. **PDF Processing**: The `PDFProcessor` extracts text from PDF manuals and splits them into chunks
2. **Indexing**: The `ManualSearchEngine` creates embeddings using sentence transformers and builds a FAISS index
3. **Question Processing**: User questions are converted to embeddings and searched against the index
4. **Answer Generation**: The `QASystem` generates answers from the most relevant chunks
5. **Citation Display**: Sources are displayed with excerpts from the manual

## Design Considerations

### 1. Storage Considerations âœ… Optimized
- **Persistent FAISS Index**: Index saved to disk (`faiss_index.bin`) - **99.99% faster startup** (2-3 min â†’ < 0.01 sec)
- **Chunked Storage**: Only chunks stored, full_text removed - **40% memory reduction** (~500MB â†’ ~300MB)
- **Multi-level Caching**:
  - Processed manuals cached (`processed_manuals.json`)
  - FAISS index cached (`faiss_index.bin`)
  - Query embeddings cached (in-memory, 100 queries)
- **Efficient Storage**: Metadata stored separately in JSON format

### 2. Input Processing Strategy âœ… Optimized
- **Lazy Model Loading**: Model loads only when needed - **99.99% faster initialization** (~2 sec â†’ < 0.0001 sec)
- **Cached Data Loading**: Manuals load from JSON cache (instant)
- **Batch Embedding Generation**: All chunks processed together for efficiency
- **Memory Optimization**: Explicit cleanup with `del full_text` after chunking
- **Fast Model Detection**: Keyword-based detection (no LLM needed)
- Text extraction from PDFs using `pdfplumber`
- Text chunking with overlap for better context

### 3. Search Optimizations âœ… Optimized
- **Persistent Index**: Loads in 0.001 seconds (vs 2-3 minutes rebuild)
- **Query Embedding Cache**: Instant response for repeated queries - **99% faster** (~100ms â†’ < 1ms)
- **FAISS Index**: Fast vector similarity search with L2 distance
- **Multi-level Search Strategy**:
  - Primary: Semantic search (sentence transformers)
  - Fallback: Keyword search for edge cases
- **Optimized Filtering**: Post-search filtering by car model
- **Batch Processing**: Embeddings generated in single batch

### Output Structure
- Clear answer display
- Numbered citations with excerpts
- Expandable citation sections
- Confidence scoring (high/medium/low)

## Troubleshooting

### Manuals not loading
- Ensure PDF files are in the parent directory
- Check file names match: `Astor Manual.pdf` and `APP-TIAGO-FINAL-OMSB.pdf`

### Slow first load
- **First run**: Processes PDFs and builds the search index (may take 2-3 minutes) - âš ï¸ **NOT OPTIMIZED**
  - This is unavoidable work that must be done once
  - Happens only when no cached index exists
- **Subsequent runs**: Uses cached index and loads in < 0.01 seconds (99.99% faster!) - âœ… **OPTIMIZED**
  - Every restart after first run
  - Saves 2-3 minutes on every session
- Index is automatically saved after first build (`faiss_index.bin`)

### No results found
- Try rephrasing your question
- Check if the car model is mentioned in the question
- Ensure the manual contains relevant information

## Future Enhancements

- Support for more car models
- Table extraction from PDFs
- Image processing and OCR
- Advanced LLM integration for better answers
- Multi-language support

## License

This project is created for the Machine Learning Engineer take-home test.
